{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c86a9909",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-12T15:24:21.628682Z",
     "iopub.status.busy": "2024-09-12T15:24:21.627993Z",
     "iopub.status.idle": "2024-09-12T15:24:22.533395Z",
     "shell.execute_reply": "2024-09-12T15:24:22.532527Z"
    },
    "papermill": {
     "duration": 0.9136,
     "end_time": "2024-09-12T15:24:22.535679",
     "exception": false,
     "start_time": "2024-09-12T15:24:21.622079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/uuuuuu/train_folds.csv\n",
      "/kaggle/input/uuuuuu/train_dataset.csv\n",
      "/kaggle/input/uuuuuu/test_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8be07cc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T15:24:22.546164Z",
     "iopub.status.busy": "2024-09-12T15:24:22.545330Z",
     "iopub.status.idle": "2024-09-12T15:24:37.612138Z",
     "shell.execute_reply": "2024-09-12T15:24:37.610723Z"
    },
    "papermill": {
     "duration": 15.07432,
     "end_time": "2024-09-12T15:24:37.614362",
     "exception": false,
     "start_time": "2024-09-12T15:24:22.540042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wtfml\r\n",
      "  Downloading wtfml-0.0.3-py3-none-any.whl.metadata (808 bytes)\r\n",
      "Requirement already satisfied: scikit-learn>=0.22.1 in /opt/conda/lib/python3.10/site-packages (from wtfml) (1.2.2)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22.1->wtfml) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22.1->wtfml) (1.14.0)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22.1->wtfml) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22.1->wtfml) (3.5.0)\r\n",
      "Downloading wtfml-0.0.3-py3-none-any.whl (10 kB)\r\n",
      "Installing collected packages: wtfml\r\n",
      "Successfully installed wtfml-0.0.3\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install wtfml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15c628d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T15:24:37.625558Z",
     "iopub.status.busy": "2024-09-12T15:24:37.625200Z",
     "iopub.status.idle": "2024-09-12T15:24:45.023017Z",
     "shell.execute_reply": "2024-09-12T15:24:45.022045Z"
    },
    "papermill": {
     "duration": 7.406176,
     "end_time": "2024-09-12T15:24:45.025458",
     "exception": false,
     "start_time": "2024-09-12T15:24:37.619282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import albumentations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from torch.nn import functional as F\n",
    "from wtfml.utils import EarlyStopping\n",
    "from wtfml.engine import Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afc79304",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T15:24:45.037741Z",
     "iopub.status.busy": "2024-09-12T15:24:45.037186Z",
     "iopub.status.idle": "2024-09-12T15:24:45.067972Z",
     "shell.execute_reply": "2024-09-12T15:24:45.067235Z"
    },
    "papermill": {
     "duration": 0.039334,
     "end_time": "2024-09-12T15:24:45.069920",
     "exception": false,
     "start_time": "2024-09-12T15:24:45.030586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import cv2\n",
    "import albumentations as A\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, pixel_arrays, targets, resize=None, augmentations=None):\n",
    "        self.pixel_arrays = pixel_arrays\n",
    "        self.targets = targets\n",
    "        self.resize = resize\n",
    "        self.augmentations = augmentations\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        if self.face_cascade.empty():\n",
    "            raise IOError('Failed to load Haar cascade file.')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pixel_arrays)\n",
    "\n",
    "    def preprocess_image(self, image):\n",
    "        # Convert the 1D array to a 2D grayscale image\n",
    "        image = np.array(image, dtype=np.float32).reshape(48,48)\n",
    "        \n",
    "        # Convert to 8-bit grayscale image\n",
    "        image = (image * 255).astype(np.uint8)  # Assuming the original image is normalized\n",
    "        \n",
    "        # Ensure image is in grayscale\n",
    "        if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detect face(s)\n",
    "        faces = self.face_cascade.detectMultiScale(image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "        \n",
    "        if len(faces) == 0:\n",
    "            # If no faces detected, return original image or handle it as required\n",
    "            return image\n",
    "        \n",
    "        # Extract the first detected face (or handle multiple faces as needed)\n",
    "        (x, y, w, h) = faces[0]\n",
    "        face = image[y:y+h, x:x+w]\n",
    "        \n",
    "        # Resize the extracted face region to the desired size\n",
    "        face = cv2.resize(face, (224, 244))\n",
    "        \n",
    "        return face\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.preprocess_image(self.pixel_arrays[idx])\n",
    "        \n",
    "        # Convert to RGB if necessary (add an extra channel dimension)\n",
    "        if len(image.shape) == 2:\n",
    "            image = np.repeat(image[:, :, np.newaxis], 3, axis=2)  # Convert grayscale to RGB\n",
    "\n",
    "        # Apply augmentations if specified\n",
    "        if self.augmentations:\n",
    "            augmented = self.augmentations(image=image)\n",
    "            image = augmented['image']\n",
    "        \n",
    "        # Convert image to PyTorch tensor and permute to (3, new_size, new_size) format\n",
    "        image = torch.tensor(image, dtype=torch.float32)  # Create tensor\n",
    "        if len(image.shape) == 3:\n",
    "            image = image.permute(2, 0, 1)  # For RGB, shape becomes (3, new_size, new_size)\n",
    "        elif len(image.shape) == 2:\n",
    "            # Add a channel dimension (1) if grayscale\n",
    "            image = image.unsqueeze(0)  # (1, new_size, new_size)\n",
    "            image = image.expand(3, -1, -1)  # Expand to (3, new_size, new_size)\n",
    "        \n",
    "        target = torch.tensor(self.targets[idx], dtype=torch.long)\n",
    "        \n",
    "        return image, target\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Engine:\n",
    "    @staticmethod\n",
    "    def train(data_loader, model, optimizer, device, scheduler=None, accumulation_steps=1, fp16=False):\n",
    "        model.train()\n",
    "        losses = AverageMeter()\n",
    "        scaler = torch.cuda.amp.GradScaler() if fp16 else None\n",
    "        \n",
    "        if accumulation_steps > 1:\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "        for batch_idx, (images, targets) in enumerate(tk0):\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with torch.set_grad_enabled(True):\n",
    "                if fp16:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        outputs = model(images)\n",
    "                        loss = FocalLoss()(outputs, targets)\n",
    "                    scaler.scale(loss).backward()\n",
    "                else:\n",
    "                    outputs = model(images)\n",
    "                    loss = FocalLoss()(outputs, targets)\n",
    "                    loss.backward()\n",
    "\n",
    "                if (batch_idx + 1) % accumulation_steps == 0:\n",
    "                    scaler.step(optimizer) if fp16 else optimizer.step()\n",
    "                    if scheduler:\n",
    "                        scheduler.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "            losses.update(loss.item(), data_loader.batch_size)\n",
    "            tk0.set_postfix(loss=losses.avg)\n",
    "        \n",
    "        return losses.avg\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluate(data_loader, model, device, use_tpu=False):\n",
    "        losses = AverageMeter()\n",
    "        final_predictions = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            tk0 = tqdm(data_loader, total=len(data_loader), disable=use_tpu)\n",
    "            for b_idx, data in enumerate(tk0):\n",
    "                images, targets = data  # Adjust if your data format is different\n",
    "\n",
    "                # Move tensors to device\n",
    "                images = images.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                predictions, loss = model(images, targets)\n",
    "                predictions = predictions.cpu()\n",
    "                losses.update(loss.item(), images.size(0))\n",
    "                final_predictions.append(predictions)\n",
    "                tk0.set_postfix(loss=losses.avg)\n",
    "\n",
    "        # Concatenate all predictions and convert to NumPy array\n",
    "        final_predictions = torch.cat(final_predictions).numpy()\n",
    "        return final_predictions, losses.avg\n",
    "    def predict(data_loader, model, device, use_tpu=False):\n",
    "        model.eval()\n",
    "        final_predictions = []\n",
    "        with torch.no_grad():\n",
    "            tk0 = tqdm(data_loader, total=len(data_loader), disable=use_tpu)\n",
    "            for b_idx, data in enumerate(tk0):\n",
    "                inputs, _ = data  # Unpack data\n",
    "                inputs = inputs.to(device)\n",
    "                predictions = model(inputs) \n",
    "                predictions = F.softmax(predictions,dim = 1)# Assume model returns only predictions\n",
    "                final_predictions.append(predictions.cpu())\n",
    "                tk0.set_postfix()\n",
    "        return torch.cat(final_predictions).numpy()\n",
    "        # Concatenate all predictions and convert to numpy array\n",
    "        return torch.cat(final_predictions).numpy()\n",
    "class AverageMeter():\n",
    "        def __init__(self):\n",
    "            self.reset()\n",
    "\n",
    "        def reset(self):\n",
    "            self.val = 0\n",
    "            self.avg = 0\n",
    "            self.sum = 0\n",
    "            self.count = 0\n",
    "\n",
    "        def update(self, val, n=1):\n",
    "            self.val = val\n",
    "            self.sum += val * n\n",
    "            self.count += n\n",
    "            self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63674726",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T15:24:45.080946Z",
     "iopub.status.busy": "2024-09-12T15:24:45.080642Z",
     "iopub.status.idle": "2024-09-12T15:24:45.096921Z",
     "shell.execute_reply": "2024-09-12T15:24:45.096115Z"
    },
    "papermill": {
     "duration": 0.023837,
     "end_time": "2024-09-12T15:24:45.098769",
     "exception": false,
     "start_time": "2024-09-12T15:24:45.074932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from torch.utils.data import DataLoader\n",
    "def train(fold):\n",
    "    df = pd.read_csv(\"/kaggle/input/uuuuuu/train_folds.csv\")\n",
    "    device = \"cuda\"\n",
    "    epochs = 50\n",
    "    train_bs = 16\n",
    "    valid_bs = 16\n",
    "\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    train_pixels = df_train['pixels'].apply(lambda x: np.fromstring(x, sep=' ', dtype=np.float32))\n",
    "    train_targets = df_train['emotion'].values\n",
    "\n",
    "    valid_pixels = df_valid['pixels'].apply(lambda x: np.fromstring(x, sep=' ', dtype=np.float32))\n",
    "    valid_targets = df_valid['emotion'].values\n",
    "\n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    train_aug = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=299, width=299),  # Resize images to 224x224\n",
    "        A.Normalize(mean=mean, std=std, max_pixel_value=255.0, always_apply=True),\n",
    "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15),\n",
    "        A.HorizontalFlip(p=0.5)\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    valid_aug = A.Compose(\n",
    "        [\n",
    "        A.Resize(height=299, width=299),  # Resize images to 224x224\n",
    "        A.Normalize(mean=mean, std=std, max_pixel_value=255.0, always_apply=True)\n",
    "        ]\n",
    "    )\n",
    "    train_dataset = CustomImageDataset(\n",
    "        pixel_arrays=train_pixels,\n",
    "        targets=train_targets,\n",
    "        resize=(299, 299),  # New size\n",
    "        augmentations=train_aug,\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=16, shuffle=True, num_workers=4\n",
    "    )\n",
    "\n",
    "    valid_dataset = CustomImageDataset(\n",
    "        pixel_arrays=valid_pixels,\n",
    "        targets=valid_targets,\n",
    "        resize=(299, 299),  # New size\n",
    "        augmentations=valid_aug,\n",
    "    )\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset, batch_size=16, shuffle=False, num_workers=4\n",
    "    )\n",
    "    model = EF(num_classes= 7,pretrained='imagenet')\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        patience=3,\n",
    "        threshold=0.001,\n",
    "        mode=\"max\"\n",
    "    )\n",
    "\n",
    "    es = EarlyStopping(patience=5, mode=\"max\")\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = Engine.train(train_loader, model,optimizer,\n",
    "        device,\n",
    "        scheduler=None,\n",
    "        accumulation_steps=1,\n",
    "        fp16=False)\n",
    "        predictions, valid_loss = Engine.evaluate(\n",
    "            valid_loader, model, device=device\n",
    "        )\n",
    "        final_predictions = np.argmax(np.vstack(predictions), axis=1)\n",
    "        valid_targets = np.array(valid_targets)  # Ensure targets are in the right format\n",
    "    \n",
    "    # Calculate accuracy\n",
    "        accuracy = metrics.accuracy_score(valid_targets, final_predictions)\n",
    "        print(f\"Epoch = {epoch}, Accuracy = {accuracy:.4f}\")\n",
    "    \n",
    "    # Update the learning rate scheduler\n",
    "        scheduler.step(accuracy)\n",
    "    \n",
    "    # Early Stopping\n",
    "        es(accuracy, model, model_path=f\"model_fold_EFb6F{fold}.bin\")\n",
    "        if es.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "    oof_data = {\n",
    "        'id': df_valid.index,  # Use the index to map back to the original data\n",
    "        'true_emotion': valid_targets,\n",
    "        'pred_emotion': final_predictions,\n",
    "        'fold': fold\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(oof_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04636d9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T15:24:45.109018Z",
     "iopub.status.busy": "2024-09-12T15:24:45.108729Z",
     "iopub.status.idle": "2024-09-12T15:25:01.031752Z",
     "shell.execute_reply": "2024-09-12T15:25:01.030358Z"
    },
    "papermill": {
     "duration": 15.930839,
     "end_time": "2024-09-12T15:25:01.034233",
     "exception": false,
     "start_time": "2024-09-12T15:24:45.103394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet_pytorch\r\n",
      "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet_pytorch) (2.4.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (3.15.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (1.13.2)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (2024.6.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet_pytorch) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\r\n",
      "Building wheels for collected packages: efficientnet_pytorch\r\n",
      "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16427 sha256=faaa0fa83a81a7825b13f51dd0b84c758ffb34d6d7023a5d2598cd4964ac17dc\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\r\n",
      "Successfully built efficientnet_pytorch\r\n",
      "Installing collected packages: efficientnet_pytorch\r\n",
      "Successfully installed efficientnet_pytorch-0.7.1\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8151441c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T15:25:01.047888Z",
     "iopub.status.busy": "2024-09-12T15:25:01.047534Z",
     "iopub.status.idle": "2024-09-12T15:25:01.062205Z",
     "shell.execute_reply": "2024-09-12T15:25:01.061522Z"
    },
    "papermill": {
     "duration": 0.023908,
     "end_time": "2024-09-12T15:25:01.064255",
     "exception": false,
     "start_time": "2024-09-12T15:25:01.040347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "class EF(nn.Module):\n",
    "    def __init__(self, num_classes=7, model_name='efficientnet-b6', pretrained='imagenet'):\n",
    "        super(EF, self).__init__()\n",
    "        \n",
    "        # Load the pre-trained EfficientNet model\n",
    "        self.base_model = EfficientNet.from_pretrained(model_name) if pretrained == 'imagenet' else EfficientNet.from_name(model_name)\n",
    "        \n",
    "        # Replace the final fully connected layer with the new layer for multi-class classification\n",
    "        in_features = self.base_model._fc.in_features\n",
    "        self.base_model._fc = nn.Linear(in_features, num_classes)\n",
    "    \n",
    "    def forward(self, image, targets=None):\n",
    "        batch_size = image.size(0)\n",
    "        \n",
    "        # Forward pass through the base model\n",
    "        out = self.base_model(image)\n",
    "        \n",
    "        # If targets are provided, calculate the loss\n",
    "        if targets is not None:\n",
    "            loss = FocalLoss()(out, targets)\n",
    "            return out, loss\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab295f47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T15:25:01.076834Z",
     "iopub.status.busy": "2024-09-12T15:25:01.076538Z",
     "iopub.status.idle": "2024-09-12T15:25:01.084343Z",
     "shell.execute_reply": "2024-09-12T15:25:01.083489Z"
    },
    "papermill": {
     "duration": 0.016298,
     "end_time": "2024-09-12T15:25:01.086316",
     "exception": false,
     "start_time": "2024-09-12T15:25:01.070018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = 1e-12  # prevent training from NaN-loss errors\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        \"\"\"\n",
    "        logits: [batch_size, num_classes]\n",
    "        target: [batch_size] (true class indices, not one-hot)\n",
    "        \"\"\"\n",
    "        # Compute softmax over logits to get the class probabilities\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        \n",
    "        # Gather the probabilities of the true class (index-based selection)\n",
    "        probs_target_class = probs.gather(1, target.unsqueeze(1)).squeeze(1) + self.epsilon\n",
    "        \n",
    "        # Compute the log of the selected probabilities\n",
    "        log_pt = torch.log(probs_target_class)\n",
    "        \n",
    "        # Calculate the focal loss (focuses more on hard examples)\n",
    "        focal_loss = -1 * self.alpha * (1 - probs_target_class) ** self.gamma * log_pt\n",
    "        \n",
    "        return torch.mean(focal_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62def81a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T15:25:01.098261Z",
     "iopub.status.busy": "2024-09-12T15:25:01.097968Z",
     "iopub.status.idle": "2024-09-12T23:23:37.074825Z",
     "shell.execute_reply": "2024-09-12T23:23:37.073564Z"
    },
    "papermill": {
     "duration": 28715.985695,
     "end_time": "2024-09-12T23:23:37.077478",
     "exception": false,
     "start_time": "2024-09-12T15:25:01.091783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b6-c76e70fd.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b6-c76e70fd.pth\n",
      "100%|██████████| 165M/165M [00:00<00:00, 260MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:54<00:00,  1.07it/s, loss=1.12]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.79it/s, loss=0.891]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, Accuracy = 0.5010\n",
      "Validation score improved (-inf --> 0.501). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.742]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=0.726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, Accuracy = 0.5590\n",
      "Validation score improved (0.501 --> 0.559). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.511]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=0.698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 2, Accuracy = 0.5610\n",
      "Validation score improved (0.559 --> 0.561). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.339]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.78it/s, loss=0.714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 3, Accuracy = 0.5820\n",
      "Validation score improved (0.561 --> 0.582). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.225]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.78it/s, loss=0.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 4, Accuracy = 0.5430\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.159]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=0.886]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 5, Accuracy = 0.5750\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.127]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.78it/s, loss=0.865]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 6, Accuracy = 0.5660\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0887]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=0.957]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 7, Accuracy = 0.5730\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0646]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=0.909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 8, Accuracy = 0.5850\n",
      "Validation score improved (0.582 --> 0.585). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0491]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=0.897]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 9, Accuracy = 0.5950\n",
      "Validation score improved (0.585 --> 0.595). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0404]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=0.902]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 10, Accuracy = 0.5930\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0384]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=0.913]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 11, Accuracy = 0.5980\n",
      "Validation score improved (0.595 --> 0.598). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0351]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.78it/s, loss=0.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 12, Accuracy = 0.6010\n",
      "Validation score improved (0.598 --> 0.601). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0326]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.79it/s, loss=0.917]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 13, Accuracy = 0.6010\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0348]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=0.927]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 14, Accuracy = 0.5950\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0273]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.79it/s, loss=0.938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 15, Accuracy = 0.5950\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0277]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.78it/s, loss=0.945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 16, Accuracy = 0.5950\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0267]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=0.942]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 17, Accuracy = 0.5900\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "Loaded pretrained weights for efficientnet-b6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=1.12]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=0.867]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, Accuracy = 0.4940\n",
      "Validation score improved (-inf --> 0.494). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.715]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=0.739]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, Accuracy = 0.5490\n",
      "Validation score improved (0.494 --> 0.549). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.5]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.75it/s, loss=0.771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 2, Accuracy = 0.5080\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.326]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.75it/s, loss=0.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 3, Accuracy = 0.5430\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.2]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.75it/s, loss=0.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 4, Accuracy = 0.5570\n",
      "Validation score improved (0.549 --> 0.557). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.131]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=0.877]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 5, Accuracy = 0.5530\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.109]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.78it/s, loss=0.978]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 6, Accuracy = 0.5560\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.05it/s, loss=0.0959]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=0.953]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 7, Accuracy = 0.5600\n",
      "Validation score improved (0.557 --> 0.56). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0725]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.75it/s, loss=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 8, Accuracy = 0.5730\n",
      "Validation score improved (0.56 --> 0.573). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0775]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=1.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 9, Accuracy = 0.5640\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0618]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=1.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 10, Accuracy = 0.5430\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0529]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.78it/s, loss=1.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 11, Accuracy = 0.5690\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0486]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 12, Accuracy = 0.5550\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.033]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=1.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 13, Accuracy = 0.5740\n",
      "Validation score improved (0.573 --> 0.574). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0334]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.78it/s, loss=1.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 14, Accuracy = 0.5730\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0266]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.75it/s, loss=1.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 15, Accuracy = 0.5780\n",
      "Validation score improved (0.574 --> 0.578). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0237]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.75it/s, loss=1.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 16, Accuracy = 0.5740\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0225]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=1.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 17, Accuracy = 0.5800\n",
      "Validation score improved (0.578 --> 0.58). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0178]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=1.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 18, Accuracy = 0.5810\n",
      "Validation score improved (0.58 --> 0.581). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0152]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=1.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 19, Accuracy = 0.5830\n",
      "Validation score improved (0.581 --> 0.583). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.05it/s, loss=0.017]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=1.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 20, Accuracy = 0.5730\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0125]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=1.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 21, Accuracy = 0.5760\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0129]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=1.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 22, Accuracy = 0.5770\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0139]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=1.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 23, Accuracy = 0.5850\n",
      "Validation score improved (0.583 --> 0.585). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0131]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.74it/s, loss=1.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 24, Accuracy = 0.5840\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0115]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=1.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 25, Accuracy = 0.5790\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0115]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 26, Accuracy = 0.5860\n",
      "Validation score improved (0.585 --> 0.586). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.00833]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 27, Accuracy = 0.5910\n",
      "Validation score improved (0.586 --> 0.591). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.012]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 28, Accuracy = 0.5790\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0107]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 29, Accuracy = 0.5810\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0101]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 30, Accuracy = 0.5780\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.00763]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=1.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 31, Accuracy = 0.5810\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.05it/s, loss=0.0118]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=1.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 32, Accuracy = 0.5810\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "Loaded pretrained weights for efficientnet-b6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=1.14]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=0.855]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, Accuracy = 0.5190\n",
      "Validation score improved (-inf --> 0.519). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.76]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.75it/s, loss=0.767]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, Accuracy = 0.5400\n",
      "Validation score improved (0.519 --> 0.54). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.522]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=0.716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 2, Accuracy = 0.5700\n",
      "Validation score improved (0.54 --> 0.57). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.335]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.75it/s, loss=0.749]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 3, Accuracy = 0.5860\n",
      "Validation score improved (0.57 --> 0.586). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.222]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.72it/s, loss=0.807]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 4, Accuracy = 0.5880\n",
      "Validation score improved (0.586 --> 0.588). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.153]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=0.868]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 5, Accuracy = 0.5800\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.117]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.75it/s, loss=0.879]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 6, Accuracy = 0.5940\n",
      "Validation score improved (0.588 --> 0.594). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0943]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=0.908]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 7, Accuracy = 0.5930\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0782]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.75it/s, loss=0.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 8, Accuracy = 0.5920\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.05it/s, loss=0.0602]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.74it/s, loss=0.981]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 9, Accuracy = 0.5810\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0744]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.75it/s, loss=0.982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 10, Accuracy = 0.5670\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.05it/s, loss=0.0426]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.74it/s, loss=0.954]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 11, Accuracy = 0.5840\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "Loaded pretrained weights for efficientnet-b6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=1.11]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.75it/s, loss=0.869]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, Accuracy = 0.5050\n",
      "Validation score improved (-inf --> 0.505). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.724]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.74it/s, loss=0.754]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, Accuracy = 0.5270\n",
      "Validation score improved (0.505 --> 0.527). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.509]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.75it/s, loss=0.76]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 2, Accuracy = 0.5350\n",
      "Validation score improved (0.527 --> 0.535). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.329]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.73it/s, loss=0.783]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 3, Accuracy = 0.5600\n",
      "Validation score improved (0.535 --> 0.56). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.224]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=0.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 4, Accuracy = 0.5620\n",
      "Validation score improved (0.56 --> 0.562). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.155]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=0.874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 5, Accuracy = 0.5460\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.05it/s, loss=0.12]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=0.971]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 6, Accuracy = 0.5720\n",
      "Validation score improved (0.562 --> 0.572). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0958]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=0.951]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 7, Accuracy = 0.5740\n",
      "Validation score improved (0.572 --> 0.574). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0816]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=1.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 8, Accuracy = 0.5620\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0695]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=1.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 9, Accuracy = 0.5730\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0601]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.74it/s, loss=1.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 10, Accuracy = 0.5650\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0567]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.78it/s, loss=1.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 11, Accuracy = 0.5620\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0378]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=1.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 12, Accuracy = 0.5750\n",
      "Validation score improved (0.574 --> 0.575). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0356]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=1.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 13, Accuracy = 0.5730\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0299]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=1.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 14, Accuracy = 0.5760\n",
      "Validation score improved (0.575 --> 0.576). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.05it/s, loss=0.0235]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=1.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 15, Accuracy = 0.5800\n",
      "Validation score improved (0.576 --> 0.58). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0271]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=1.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 16, Accuracy = 0.5860\n",
      "Validation score improved (0.58 --> 0.586). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0214]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.75it/s, loss=1.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 17, Accuracy = 0.5900\n",
      "Validation score improved (0.586 --> 0.59). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0165]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=1.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 18, Accuracy = 0.5840\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0222]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=1.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 19, Accuracy = 0.5790\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0149]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.78it/s, loss=1.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 20, Accuracy = 0.5810\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0174]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=1.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 21, Accuracy = 0.5820\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.013]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.78it/s, loss=1.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 22, Accuracy = 0.5820\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "Loaded pretrained weights for efficientnet-b6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=1.12]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=0.932]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, Accuracy = 0.4780\n",
      "Validation score improved (-inf --> 0.478). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.726]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.78it/s, loss=0.798]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, Accuracy = 0.5580\n",
      "Validation score improved (0.478 --> 0.558). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.486]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=0.813]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 2, Accuracy = 0.5480\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.328]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.78it/s, loss=0.912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 3, Accuracy = 0.5430\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.213]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=0.931]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 4, Accuracy = 0.5540\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.152]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.78it/s, loss=0.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 5, Accuracy = 0.5660\n",
      "Validation score improved (0.558 --> 0.566). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.118]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=1.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 6, Accuracy = 0.5490\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0955]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=1.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 7, Accuracy = 0.5670\n",
      "Validation score improved (0.566 --> 0.567). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0843]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 8, Accuracy = 0.5740\n",
      "Validation score improved (0.567 --> 0.574). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0703]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 9, Accuracy = 0.5800\n",
      "Validation score improved (0.574 --> 0.58). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0568]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=1.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 10, Accuracy = 0.5790\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0681]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=1.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 11, Accuracy = 0.5620\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0499]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=1.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 12, Accuracy = 0.5670\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0393]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.75it/s, loss=1.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 13, Accuracy = 0.5800\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0376]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=1.18]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 14, Accuracy = 0.5810\n",
      "Validation score improved (0.58 --> 0.581). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0268]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=1.17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 15, Accuracy = 0.5750\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0225]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=1.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 16, Accuracy = 0.5820\n",
      "Validation score improved (0.581 --> 0.582). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0188]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=1.17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 17, Accuracy = 0.5810\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.0204]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.74it/s, loss=1.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 18, Accuracy = 0.5910\n",
      "Validation score improved (0.582 --> 0.591). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0168]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.75it/s, loss=1.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 19, Accuracy = 0.5960\n",
      "Validation score improved (0.591 --> 0.596). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0157]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=1.17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 20, Accuracy = 0.5980\n",
      "Validation score improved (0.596 --> 0.598). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0174]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.74it/s, loss=1.17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 21, Accuracy = 0.6000\n",
      "Validation score improved (0.598 --> 0.6). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0132]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.77it/s, loss=1.18]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 22, Accuracy = 0.6000\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0136]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.75it/s, loss=1.17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 23, Accuracy = 0.5990\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.0108]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.73it/s, loss=1.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 24, Accuracy = 0.5920\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.00998]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.76it/s, loss=1.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 25, Accuracy = 0.5950\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:56<00:00,  1.06it/s, loss=0.012]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.72it/s, loss=1.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 26, Accuracy = 0.5950\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X = np.empty((0, 4))  # Initialize an empty array with 7 columns to match df.values\n",
    "\n",
    "for i in range(0, 5):\n",
    "    df = train(i)  # Assuming train(1) returns a DataFrame with 7 columns\n",
    "    df.to_csv(f\"oof1EFOCAL-{i}.csv\", index=False, header=False)\n",
    "    if len(df.columns)!=4:\n",
    "        df = df.drop('Unnamed: 0',axis = 1)    \n",
    "    X = np.concatenate((X, df.values))  # Concatenate new data to X\n",
    "\n",
    "# Convert the final result into a DataFrame and save to CSV\n",
    "df = pd.DataFrame(X)\n",
    "df.to_csv('EFFb6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c4ee859",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T23:23:48.976852Z",
     "iopub.status.busy": "2024-09-12T23:23:48.976475Z",
     "iopub.status.idle": "2024-09-12T23:23:48.985918Z",
     "shell.execute_reply": "2024-09-12T23:23:48.985064Z"
    },
    "papermill": {
     "duration": 5.86082,
     "end_time": "2024-09-12T23:23:48.987762",
     "exception": false,
     "start_time": "2024-09-12T23:23:43.126942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(fold):\n",
    "    df = pd.read_csv(\"/kaggle/input/uuuuuu/test_dataset.csv\")\n",
    "    device = \"cuda\"\n",
    "    model_path=f\"model_fold_EFb6F{fold}.bin\"\n",
    "    test_pixels = df['pixels'].apply(lambda x: np.fromstring(x, sep=' ', dtype=np.float32))                 \n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    aug = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Resize(height=299, width=299),\n",
    "            albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True)\n",
    "        ]\n",
    "    )\n",
    "                                      \n",
    "    targets = np.zeros(len(df))\n",
    "    test_dataset = CustomImageDataset(\n",
    "        pixel_arrays=test_pixels,\n",
    "        targets=targets,\n",
    "        resize=None,\n",
    "        augmentations=aug,\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=16, shuffle=False, num_workers=4\n",
    "    )\n",
    "\n",
    "    model = model = EF(pretrained='imagenet')\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "\n",
    "    predictions = Engine.predict(test_loader, model, device=device)\n",
    "    predictions = np.vstack((predictions))\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e14e7ec1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T23:24:00.667658Z",
     "iopub.status.busy": "2024-09-12T23:24:00.666970Z",
     "iopub.status.idle": "2024-09-12T23:27:40.351109Z",
     "shell.execute_reply": "2024-09-12T23:27:40.349898Z"
    },
    "papermill": {
     "duration": 227.758996,
     "end_time": "2024-09-12T23:27:42.576630",
     "exception": false,
     "start_time": "2024-09-12T23:23:54.817634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/4232482971.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n",
      "100%|██████████| 157/157 [00:41<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/4232482971.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n",
      "100%|██████████| 157/157 [00:40<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/4232482971.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n",
      "100%|██████████| 157/157 [00:41<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/4232482971.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n",
      "100%|██████████| 157/157 [00:40<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/4232482971.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n",
      "100%|██████████| 157/157 [00:41<00:00,  3.82it/s]\n"
     ]
    }
   ],
   "source": [
    "P1 = predict(0)\n",
    "P2 = predict(1)\n",
    "P3 = predict(2)\n",
    "P4 = predict(3)\n",
    "P5 = predict(4)\n",
    "P = (P1 + P2 +P3 +P4 + P5)/5\n",
    "df = pd.DataFrame(P)\n",
    "df.to_csv('EFFb6.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5687451,
     "sourceId": 9376270,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29012.819802,
   "end_time": "2024-09-12T23:27:51.337550",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-12T15:24:18.517748",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
